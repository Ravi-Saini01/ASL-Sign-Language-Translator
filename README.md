<h1>ğŸ–ï¸ ASL Sign Language Translator</h1>

ASL â†’ Text & Speech (Camera-Based)

A real-time American Sign Language (ASL) Translator that converts ASL hand gestures into readable text and spoken speech using a webcam.
The system is trained on the Kaggle ASL Alphabet Dataset and provides a modern Streamlit interface for easy interaction.

This project is designed for academic use, final-year demos, and resume portfolios.

ğŸš€ Features

ğŸ“· Real-time ASL recognition using webcam

ğŸ§  CNN-based deep learning model

âŒ¨ï¸ Keyboard-controlled character capture

ğŸ“ Word & sentence formation

ğŸ”Š Text-to-Speech output (no external media player)

ğŸ¨ Clean, modern Streamlit UI

ğŸ“Š Stable prediction using majority voting

âŒ No retraining required during use

<h1>ğŸ§  How It Works (Pipeline)</h1>
Webcam
   â†“
Hand Image (ROI)
   â†“
CNN Model (Trained on ASL Dataset)
   â†“
Stable Prediction (Majority Voting)
   â†“
Keyboard-Controlled Text Builder
   â†“
Text-to-Speech Output

<h1>ğŸ“Š Dataset</h1>
Source: Kaggle â€“ ASL Alphabet Dataset

Classes: 29

Aâ€“Z

space

delete

nothing

Images: ~87,000

Type: Static ASL gestures

ğŸ”— Dataset link:
https://www.kaggle.com/datasets/grassknoted/asl-alphabet

<h1>ğŸ— Project Structure</h1>

ASL-Sign-Language-Translator/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ asl_alphabet/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ asl_cnn_model.h5
â”‚   â””â”€â”€ labels.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ predict_realtime.py
â”‚
â”œâ”€â”€ asl_chart.jpg
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

<h1>âš™ï¸ Technologies Used</h1>

Python

TensorFlow / Keras

OpenCV

NumPy

Streamlit

Windows Speech API (Text-to-Speech)

<h1>âŒ¨ï¸ Controls & Usage</h1>

<b>Key</b>	                    <b>Action</b>

<b>SPACEBAR</b>	                Add detected ASL character<>
<b>BACKSPACE</b>	            Delete previous character
<b>S</b>	                    Speak the full sentence
<b>ESC</b>	                    Exit camera window

ğŸ‘‰ Characters are added only when SPACEBAR is pressed to avoid accidental input.

<h1>â–¶ï¸ How to Run the Project</h1>

<h2>1ï¸âƒ£ Install Dependencies</h2>
pip install -r requirements.txt

<h2>2ï¸âƒ£ Ensure Model Files Exist</h2>
models/
â”œâ”€â”€ asl_cnn_model.h5
â””â”€â”€ labels.json

<h2>3ï¸âƒ£ Run the Application</h2>
streamlit run app.py

<h1>ğŸ–¥ User Interface</h1>
Modern card-based Streamlit UI

Clear instructions and controls

OpenCV window for live camera feed

Optional ASL alphabet chart displayed alongside camera

<h1>ğŸ§ª Stability Improvements</h1>
To ensure accurate word formation:

âœ” Confidence thresholding

âœ” Majority voting across multiple frames

âœ” Keyboard-controlled character capture

This prevents:

Early detection

Flickering predictions

Repeated or wrong characters

<h1>âš ï¸ Limitations</h1>
Supports static ASL gestures only

Dynamic gestures (J, Z) are not covered

Facial expressions are not included

Works best with good lighting and plain background

<h1>ğŸ“œ License</h1>
This project is intended for educational and academic use only.


